{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minerva4\r\n"
     ]
    }
   ],
   "source": [
    "!hostname\n",
    "try:\n",
    "    import readline\n",
    "except ImportError:\n",
    "    print(\"Module readline not available.\")\n",
    "else:\n",
    "    import rlcompleter\n",
    "    readline.parse_and_bind(\"tab: complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports / style (run this first always)\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from IPython.core import display\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "class AwesomeError(Exception):\n",
    "     def __init__(self, value):\n",
    "         self.value = value\n",
    "         pass\n",
    "     def __str__(self):\n",
    "         return repr(self.value)\n",
    "         pass\n",
    "\n",
    "#colorbrewer2 Dark2 qualitative color table\n",
    "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
    "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
    "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
    "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
    "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
    "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843)]\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['figure.dpi'] = 150\n",
    "rcParams['axes.color_cycle'] = dark2_colors\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['patch.facecolor'] = dark2_colors[0]\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "\n",
    "\n",
    "def remove_border(axes=None, top=False, right=False, left=True, bottom=True):\n",
    "    \"\"\"\n",
    "    Minimize chartjunk by stripping out unnecesasry plot borders and axis ticks\n",
    "    \n",
    "    The top/right/left/bottom keywords toggle whether the corresponding plot border is drawn\n",
    "    \"\"\"\n",
    "    ax = axes or plt.gca()\n",
    "    ax.spines['top'].set_visible(top)\n",
    "    ax.spines['right'].set_visible(right)\n",
    "    ax.spines['left'].set_visible(left)\n",
    "    ax.spines['bottom'].set_visible(bottom)\n",
    "    \n",
    "    #turn off all ticks\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    \n",
    "    #now re-enable visibles\n",
    "    if top:\n",
    "        ax.xaxis.tick_top()\n",
    "    if bottom:\n",
    "        ax.xaxis.tick_bottom()\n",
    "    if left:\n",
    "        ax.yaxis.tick_left()\n",
    "    if right:\n",
    "        ax.yaxis.tick_right()\n",
    "        \n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import Bio as bp\n",
    "from Bio.Sequencing.Applications import BwaAlignCommandline as bwa_aln\n",
    "from Bio.Sequencing.Applications import BwaSamseCommandline as bwa_samse\n",
    "from Bio.Sequencing.Applications import BwaSampeCommandline as bwa_sampe\n",
    "from Bio.Sequencing.Applications import BwaIndexCommandline as bwa_index\n",
    "from Bio.Sequencing.Applications import BwaBwaswCommandline as bwa_bwasw\n",
    "import HTSeq as ht\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load /hpc/users/neffr01/2work/documents/scripts/greedy_partitioner.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# imports\n",
    "import os, sys, getopt\n",
    "import pysam\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "global count\n",
    "count = 0\n",
    "\n",
    "# init main\n",
    "def main(argv):\n",
    "    hairs_file = ''\n",
    "    hapcut_file = ''\n",
    "    bam_file = ''\n",
    "    out_file = ''\n",
    "    help = 'greedy_partitioner.py -h <input.hairs> -c <input.hapcut> -i <input.bam> -o <output.ann.bam>'\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv,\"h:c:i:o:\",[\"hairs=\",\"hapcut=\", \"input=\", \"output=\"])\n",
    "    except getopt.GetoptError:\n",
    "        print help\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt == '--help':\n",
    "            print help\n",
    "            sys.exit()\n",
    "        elif opt in (\"-h\", \"--hairs\"):\n",
    "            hairs_file = arg\n",
    "        elif opt in (\"-c\", \"--hapcut\"):\n",
    "            hapcut_file = arg\n",
    "        elif opt in (\"-i\", \"--input\"):\n",
    "            bam_file = arg\n",
    "        elif opt in (\"-o\", \"--output\"):\n",
    "            out_file = arg\n",
    "        else:\n",
    "            assert False, \"unhandled option\"\n",
    "\n",
    "    assert pysam.Samfile(bam_file, 'rb'), 'ERROR: Cannot open bam file for reading.'\n",
    "    assert open(bam_file + '.bai', 'rb'), 'ERROR: bam file is not indexed!'\n",
    "    bam_fp = pysam.Samfile(bam_file, 'rb')\n",
    "\n",
    "    if out_file==None:\n",
    "        out_file = bam_file + \".ann_haplotypes_\" + time.strftime(\"%m%d%y_%H%M%S\") + '.bam'\n",
    "\n",
    "    assert pysam.AlignmentFile(out_file, \"wb\", template=bam_fp), 'ERROR: Cannot open output file for writing.'\n",
    "    out_fp = pysam.AlignmentFile(out_file, \"wb\", template=bam_fp)\n",
    "\n",
    "    assert open(hairs_file), 'ERROR: Cannot access hairs file.'\n",
    "    assert open(hapcut_file), 'ERROR: Cannot open hapcut file.'\n",
    "\n",
    "    hair_reader = HairReader(hairs_file)\n",
    "    block_reader = HapCutReader(hapcut_file)\n",
    "    stats_file = hairs_file + \".interblock_stats.tsv\"\n",
    "    sys.stdout.write(\"Loaded greedy_partitoner.py, beginning execution. \\n\")\n",
    "    sys.stdout.flush()\n",
    "    tag_reads(bam_fp, hair_reader, block_reader, out_fp) #begin tagging reads\n",
    "    interblock_stats(hair_reader, block_reader, stats_file) #generate interblock stats\n",
    "    bam_fp.close()\n",
    "    out_fp.close()\n",
    "\n",
    "# end of main\n",
    "\n",
    "### CLASSES ###\n",
    "\n",
    "class BlockVariant:\n",
    "    def __init__ (self, variantline):\n",
    "        # variant_id haplotype_1 haplotype_2 chromosome position refallele variantallele genotype allele_counts:genotype_likelihoods:delta:MEC_variant\n",
    "        ll = variantline.strip().split(\"\\t\")\n",
    "        var_id, hap1, hap2, chrom, pos, r_allele, v_allele, genotype, info_str = ll\n",
    "        self.chrom, self.r_allele, self.v_allele, self.info_str = chrom, r_allele, v_allele, info_str\n",
    "        self.var_id, self.hap1, self.hap2, self.pos = int(var_id), hap1, hap2, int(pos)\n",
    "        allele_counts, genotype_likelihoods, delta, MEC_variant = info_str.split(\":\")[0:4]\n",
    "        self.ref_count, self.alt_count = map(int, allele_counts.split(\",\"))\n",
    "        gen_00, gen_01, gen_11 = map(float, genotype_likelihoods.split(\",\"))\n",
    "        self.gen_like = {\"0/0\":gen_00, \"0/1\":gen_01, \"1/1\":gen_11}\n",
    "        self.delta = float(delta)\n",
    "        self.MEC_variant = MEC_variant\n",
    "    def __repr__ (self):\n",
    "        return \"<BlockVariant, var_id: %s>\" % str(self.var_id)\n",
    "\n",
    "\n",
    "class Block:\n",
    "    def __init__ (self, blockline):\n",
    "        # \"BLOCK: offset:\" first_variant_block \"len:\" length_of_block \"phased\": phased_variants_block SPAN: \n",
    "        # lengthspanned MECscore score fragments #fragments\n",
    "\n",
    "        ll               = blockline.strip().split()\n",
    "        self.offset      = int(ll[2])\n",
    "        self.total_len   = int(ll[4])\n",
    "        self.phased      = int(ll[6])\n",
    "        self.span        = int(ll[8])\n",
    "        self.MECscore    = float(ll[10])\n",
    "        self.fragments   = int(ll[12])\n",
    "        self.variants \t = [] # default to empty\n",
    "        self.variant_ids = []\n",
    "        self.chrom = 0\n",
    "        self.start = 0\n",
    "        self.end = 0\n",
    "        self.informative_reads = []\n",
    "        self.read_count = 0\n",
    "        self.read_set = set()\n",
    "\n",
    "    def __repr__ (self):\n",
    "        return \"<Block, offset_id: %s>\" % str(self.offset)\n",
    "\n",
    "    def addVariant(self, variantline):\n",
    "        variant = BlockVariant(variantline)\n",
    "        self.variants.append(variant)\n",
    "        self.variant_ids.append(variant.var_id)\n",
    "        self.updatePosition()\n",
    "\n",
    "    def updatePosition(self): # we need to do this because sometimes the variant isn't associated with a block\n",
    "        positions = []\n",
    "        chrom = None\n",
    "        for variant in self.variants:\n",
    "            if chrom == None:\n",
    "                chrom = variant.chrom\n",
    "            positions.append(variant.pos)\n",
    "        self.chrom = chrom\n",
    "        self.start = np.min(positions)\n",
    "        self.end = np.max(positions)\n",
    "\n",
    "    def addReadsToBlock(self, read_array):\n",
    "        self.informative_reads = []\n",
    "        for read in read_array:\n",
    "            read_ids = [var[0] for block in read.blocks for var in block]\n",
    "            if len(set(read_ids).intersection(set(self.variant_ids))) > 0:\n",
    "                self.informative_reads.append(read)\n",
    "        self.read_count = len(self.informative_reads)\n",
    "        self.read_set = frozenset([x.read_id for x in self.informative_reads])\n",
    "\n",
    "    def concordance(self, input_reads):\n",
    "        ''' this should return a dict of (#T,#F) tuples per variant\n",
    "         each element is a variant's concordance with the reads\n",
    "         using the read's haplotype information, we can establish whether the read's phasing\n",
    "         is consistent with how the variant was phased '''\n",
    "        variant_concord = dict()\n",
    "        for variant in self.variants:\n",
    "            support_reads_hap2 = 0\n",
    "            against_reads_hap2 = 0\n",
    "            support_reads_hap1 = 0\n",
    "            against_reads_hap1 = 0\n",
    "            for read in input_reads:\n",
    "                if variant.var_id in read.positions:\n",
    "                    read_allele = read.alleles[read.positions.index(variant.var_id)]\n",
    "                    hapstate = read.haplotypes[self.offset]\n",
    "                    if hapstate == 2:\n",
    "                        if variant.hap2 != read_allele:\n",
    "                            against_reads_hap2 += 1\n",
    "                        else:\n",
    "                            support_reads_hap2 += 1\n",
    "                    else:\n",
    "                        if variant.hap1 != read_allele:\n",
    "                            against_reads_hap1 += 1\n",
    "                        else:\n",
    "                            support_reads_hap1 += 1\n",
    "            variant_concord[variant.var_id] = {\"hap1\": (support_reads_hap1, against_reads_hap1), \n",
    "                                               \"hap2\": (support_reads_hap2, against_reads_hap2)}\n",
    "        return variant_concord\n",
    "\n",
    "    def variant(self, var_id):\n",
    "        return next((x for x in self.variants if var_id == x.var_id), None)\n",
    "\n",
    "    def interblock_reads(self, input_reads):\n",
    "        out_reads = []\n",
    "        for read in input_reads:\n",
    "            if read.read_id not in self.read_set:\n",
    "                if read.chrom == self.chrom:\n",
    "                    if ((read.start < self.end) & (read.end > self.end)) | \\\n",
    "                        ((read.end > self.start) & (read.start < self.start)) | \\\n",
    "                        ((read.end <= self.end) & (read.start >= self.start)):\n",
    "                        out_reads.append(read)\n",
    "        return out_reads\n",
    "\n",
    "class HapCutReader:\n",
    "\n",
    "    def __init__ ( self, fn ):\n",
    "        self.fn = fn\n",
    "        self.blocks = list(self.read_file_to_blocks(fn))\n",
    "\n",
    "    def loc(self, block_id):\n",
    "        return next((x for x in self.blocks if block_id in x.variant_ids), None)\n",
    "\n",
    "    def read_file_to_blocks(self, fn):\n",
    "        with open(fn) as f:\n",
    "            currBlock = None\n",
    "            for l in f:\n",
    "                if l[0] == \"B\": # starting a new block\n",
    "                    currBlock = Block(l)\n",
    "                elif l[0] == \"*\": # ending a block\n",
    "                    yield currBlock\n",
    "                else:\n",
    "                    currBlock.addVariant(l)\n",
    "\n",
    "    def __repr__ (self):\n",
    "        return \"<HapCutReader, filename: %s>\" % self.fn                    \n",
    "\n",
    "class HapCutRead:\n",
    "\n",
    "    def __init__ (self, hairline):\n",
    "        #Column 1 is the number of consecutive set of SNPs covered by the fragment, NOT haplotype blocks.\n",
    "        #Column 2 is the fragment id. \n",
    "        #Column 3 is the offset of the first block of SNPs covered by the fragment followed by the alleles at the SNPs in this block.\n",
    "        #Column 5 is the offset of the second block of SNPs covered by the fragment followed by the alleles at the SNPs in this block.\n",
    "        #...\n",
    "        #The last column is a string with the quality values (Sanger fastq format) for all the alleles covered by the fragment (concatenated for all blocks). \n",
    "        #For example, if a read/fragment covers SNPs 2,3 and 5 with the alleles 0, 1 and 0 respectively, then the input will be:\n",
    "        #2 read_id 2 01 5 0 AAC\n",
    "        #Here AAC is the string corresponding to the quality values at the three alleles. The encoding of 0/1 is arbitrary but following the VCF format, 0 is reference and 1 is alternate. \n",
    "        hairlist = hairline.strip().split()\n",
    "        self.blockcount = 0                # this information must be determined afterwards \n",
    "        self.read_id    = hairlist[1]      # read_id\n",
    "        self.blocks     = []\t\t       # an array of tuples corresponding to blocks\n",
    "        self.positions  = []\n",
    "        self.alleles    = []\n",
    "        self.chrom      = None\n",
    "        self.start      = None\n",
    "        self.end        = None\n",
    "        self.haplotypes = dict()             # an array of {\"block_offset\":\"haplotype\"} \n",
    "                                           # after partitioning\n",
    "        for i in range(2, len(hairlist)-1, 2):\n",
    "            position = int(hairlist[i])\n",
    "            allele = hairlist[i+1]\n",
    "            block = zip(range(position, position+len(allele)), allele)\n",
    "            self.blocks.append(block)\n",
    "            self.positions.extend(range(position, position+len(allele)))\n",
    "            self.alleles.extend(allele)\n",
    "            self.qualities  = hairlist[-1]         # a matched arary of the qualities of allele calls\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<HapCutRead, read_id: %s>\" % str(self.read_id)\n",
    "\n",
    "    def haplotype_fields(self):\n",
    "        haps = \";\".join([','.join([str(key), str(self.haplotypes[key])]) for key in self.haplotypes])\n",
    "        haptag = [(\"ZH\", haps), (\"ZB\", int(self.blockcount))]\n",
    "        return haptag\n",
    "    \n",
    "    def addGenomicPositions(self, block_reader):\n",
    "        arr = []\n",
    "        chrom = None\n",
    "        for position in self.positions:\n",
    "            b = block_reader.loc(position)\n",
    "            if b == None:\n",
    "                continue\n",
    "            if chrom == None:\n",
    "                chrom = b.chrom\n",
    "            arr.append(b.variant(position).pos)\n",
    "        if len(arr) > 0:\n",
    "            self.chrom = chrom\n",
    "            self.start = np.min(arr)\n",
    "            self.end = np.max(arr)\n",
    "        else:\n",
    "            self.chrom = '*'\n",
    "            self.start = None\n",
    "            self.end = None\n",
    "    \n",
    "class HairReader:\n",
    "\n",
    "    def __init__ (self, fn):\n",
    "        self.fn = fn\n",
    "        self.reads = []\n",
    "        with open (fn) as f:\n",
    "            for l in f:\n",
    "                self.reads.append(HapCutRead(l))\n",
    "        self.read_set = frozenset([x.read_id for x in self.reads])\n",
    "\n",
    "    def __repr__ (self):\n",
    "        return \"<HairReader, filename: %s>\" % self.fn\n",
    "\n",
    "    def loc(self, read_id):\n",
    "        return next((x for x in self.reads if read_id == x.read_id))\n",
    "\n",
    "### FUNCTIONS ###\n",
    "\n",
    "'''\n",
    "\n",
    "tag_reads()\n",
    "\n",
    "Usage: Tags reads from a bam file corresponding to a particular haplotype, with haplotype\n",
    "definitions from HapCut, under the optional tag \"ZH\".\n",
    "\n",
    "Inputs:\n",
    "    bam_fp\n",
    "    A pysam.Samfile object pointing to the input file\n",
    "    hair_reader\n",
    "    A HairReader object pointing to the hairs file.\n",
    "    block_reader\n",
    "    A HapcutReader object pointing to the hapcut file.\n",
    "    out_fp\n",
    "    A pysam.AlignmentFile pointing to the output bam.\n",
    "Outputs:\n",
    "    (none - writes to out_fp)\n",
    "\n",
    "'''\n",
    "\n",
    "def tag_reads(bam_fp, hair_reader, block_reader, out_fp):\n",
    "    ''' tag_reads(bam_fp, hair_reader, block_reader, out_fp)'''\n",
    "    global count\n",
    "    for bamread in bam_fp.fetch():\n",
    "        count += 1\n",
    "    if (count % 100) == 0:\n",
    "        sys.stdout.write(\"\\rWritten %s lines to output.\" % str(count))\n",
    "        sys.stdout.flush()\n",
    "        if bamread.query_name in hair_reader.read_set:\n",
    "            read = hair_reader.loc(bamread.query_name)\n",
    "            read = greedy_partition(read, block_reader)\n",
    "            bamread.tags += read.haplotype_fields()      # add the haplotype information\n",
    "        out_fp.write(bamread)\n",
    "\n",
    "'''\n",
    "greedy_partition()\n",
    "Ryan Neff\n",
    "\n",
    "inputs:\n",
    "read\n",
    "    a HapCutRead object\n",
    "block_reader\n",
    "    of the type HapCutReader\n",
    "\n",
    "outputs:\n",
    "    the original read, now with haplotype information.\n",
    "\n",
    "translate hairfile alleles into blockvar IDs\n",
    "get alleles in each read spanning blockvars\n",
    "determine alleles for the two blocks from blockvar\n",
    "partition read based on locally most probable alignment\n",
    "\n",
    "'''\n",
    "\n",
    "def greedy_partition(read, block_reader):\n",
    "    # it turns out that the blocks provided in a hapcut file don't actually correspond to real blocks\n",
    "    # just contiguous alleles?\n",
    "    read.blocks = [] # because they are useless\n",
    "    lastBlock = -1\n",
    "    for ix, pos in enumerate(read.positions):\n",
    "        currBlock = block_reader.loc(pos)\n",
    "        if currBlock == None:\n",
    "            continue\n",
    "        currBlock = currBlock.offset\n",
    "        if currBlock != lastBlock:\n",
    "            read.blocks.append([])\n",
    "        read.blocks[-1].append((pos, read.alleles[ix]))\n",
    "        lastBlock = currBlock\n",
    "    read.blockcount = len(read.blocks)\n",
    "    for readblock in read.blocks:\n",
    "        positions = [x[0] for x in readblock]\n",
    "        alleles = [x[1] for x in readblock]\n",
    "        allele_state = []\n",
    "        offset = positions[0]\n",
    "        hap = 0\n",
    "        block = block_reader.loc(offset) #retrieve block the read is in\n",
    "        offset = block.offset\n",
    "        if block == None:\n",
    "            continue\n",
    "        for ix, varpos in enumerate(positions):\n",
    "            blockvar = block.variant(varpos)\n",
    "            if blockvar.hap1 == alleles[ix]:\n",
    "                allele_state.append(-1)\n",
    "            elif blockvar.hap2 == alleles[ix]:\n",
    "                allele_state.append(1)\n",
    "            else:\n",
    "                sys.stderr.write(\"\\nERROR: read allele matched no haplotypes.\\n\")\n",
    "                sys.stderr.write(\"\\nHair read: %s\" % read.read_id)\n",
    "                sys.stderr.write(\"\\nAlleles: %s\" % str(alleles[ix]))\n",
    "                sys.stderr.write(\"\\n Hap 1: %s, Hap 2: %s\\n\" % (blockvar.hap1, blockvar.hap2))\n",
    "                sys.stderr.flush()\n",
    "                continue\n",
    "        if len(allele_state) < 1:\n",
    "            sys.stderr.write(\"Warning: no haplotype information in read.\\n\")\n",
    "            hap = -1\n",
    "        if sum(allele_state) < 0:\n",
    "            hap = 1\n",
    "        elif sum(allele_state) > 0:\n",
    "            hap = 2\n",
    "        else:\n",
    "            hap = 0\n",
    "        read.haplotypes[offset] = hap\n",
    "    return read\n",
    "\n",
    "'''\n",
    "interblock_stats()\n",
    "\n",
    "Usage: Creates a tab-separated values file with statistics about reads overlapping\n",
    "between nearby blocks, and finds the concordance of these interblock reads\n",
    "with haplotypes in other blocks. \n",
    "\n",
    "inputs:\n",
    "    hair_reader\n",
    "        A HairReader object\n",
    "    block_reader\n",
    "        A HapcutReader object\n",
    "    out_stats\n",
    "        A string where the .tsv should be written. Defaults\n",
    "        to the hairs filename given in the input + 'interblock_stats.tsv'\n",
    "outputs:\n",
    "    none-writes to file directly\n",
    "\n",
    "'''\n",
    "\n",
    "def interblock_stats(hair_reader, block_reader, out_stats=hairs_file + \".interblock_stats.tsv\"):\n",
    "    blockdist = []\n",
    "    lastChr = None\n",
    "    lastPos = None\n",
    "    lastBlock = None\n",
    "    lastReads = set()\n",
    "    for read in hair_reader.reads:\n",
    "        if read.haplotypes == dict():\n",
    "            read = greedy_partition(read, block_reader)\n",
    "            read.addGenomicPositions(block_reader)\n",
    "    for block in block_reader.blocks:\n",
    "        if block.read_set == set():\n",
    "            block.addReadsToBlock(hair_reader.reads)\n",
    "        currBlock = block.offset\n",
    "        currChr = block.chrom\n",
    "        currPos = block.start\n",
    "        if lastBlock != None:\n",
    "            if lastChr == currChr:\n",
    "                interblock_reads = block.interblock_reads(lastBlock_obj.informative_reads)\n",
    "                row=[lastBlock, currBlock, currChr, lastPos, currPos, currPos-lastPos, \n",
    "                     len(lastBlock_obj.variant_ids), len(block.variant_ids), \n",
    "                     len(lastBlock_obj.informative_reads), len(block.informative_reads),\n",
    "                     len(interblock_reads), \n",
    "                     lastBlock_obj.concordance(lastBlock_obj.informative_reads), \n",
    "                     block.concordance(block.informative_reads)]\n",
    "                blockdist.append(row)\n",
    "            else:\n",
    "                continue\n",
    "        lastBlock = currBlock\n",
    "        lastBlock_obj = block\n",
    "        lastChr = currChr\n",
    "        lastPos = block.end\n",
    "        lastReads = currReads\n",
    "    header = ['block1', 'block2', 'chrom', 'block1_end', 'block2_start', 'distance', 'block1_variants', 'block2_variants', \n",
    "              'block1_reads', 'block2_reads', 'interblock_reads', 'block1_concordance', 'block2_concordance']\n",
    "    info = pd.DataFrame(blockdist, columns=header)\n",
    "    info.to_csv(out_stats, sep=\"\\t\")\n",
    "\n",
    "# run the program if called from the command line\n",
    "#if __name__ == \"__main__\":\n",
    "#   main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interblock statistics**\n",
    "\n",
    "* length of block\n",
    "* variant count in block\n",
    "* total reads inside block\n",
    "* Informative reads inside block\n",
    "* Distance between blocks\n",
    "* Which blocks overlap\n",
    "* Interblock reads\n",
    "    * Read count between junctions\n",
    "    * 2x2 matrix with support for linking blocks if at junction\n",
    "* Total coverage between blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#interblock distance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def interblock_stats(hair_reader, block_reader, out_stats=hairs_file + \".interblock_stats.tsv\"):\n",
    "    blockdist = []\n",
    "    lastChr = None\n",
    "    lastPos = None\n",
    "    lastBlock = None\n",
    "    lastReads = set()\n",
    "    for read in hair_reader.reads:\n",
    "        if read.haplotypes == dict():\n",
    "            read = greedy_partition(read, block_reader)\n",
    "            read.addGenomicPositions(block_reader)\n",
    "    for block in block_reader.blocks:\n",
    "        if block.read_set == set():\n",
    "            block.addReadsToBlock(hair_reader.reads)\n",
    "        currBlock = block.offset\n",
    "        currChr = block.chrom\n",
    "        currPos = block.start\n",
    "        if lastBlock != None:\n",
    "            if lastChr == currChr:\n",
    "                interblock_reads = block.interblock_reads(lastBlock_obj.informative_reads)\n",
    "                row=[lastBlock, currBlock, currChr, lastPos, currPos, currPos-lastPos, \n",
    "                     len(lastBlock_obj.variant_ids), len(block.variant_ids), \n",
    "                     len(lastBlock_obj.informative_reads), len(block.informative_reads),\n",
    "                     len(interblock_reads), \n",
    "                     lastBlock_obj.concordance(lastBlock_obj.informative_reads), \n",
    "                     block.concordance(block.informative_reads)]\n",
    "                blockdist.append(row)\n",
    "            else:\n",
    "                continue\n",
    "        lastBlock = currBlock\n",
    "        lastBlock_obj = block\n",
    "        lastChr = currChr\n",
    "        lastPos = block.end\n",
    "        lastReads = currReads\n",
    "    header = ['block1', 'block2', 'chrom', 'block1_end', 'block2_start', 'distance', 'block1_variants', 'block2_variants', \n",
    "              'block1_reads', 'block2_reads', 'interblock_reads', 'block1_concordance', 'block2_concordance']\n",
    "    info = pd.DataFrame(blockdist, columns=header)\n",
    "    info.to_csv(out_stats, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bam_fp = pysam.Samfile('/sc/orga/scratch/bashia02/collaborations/hardik_shah/jason_new/hapcut_outputs/hg002_000000F/hg002.000000F.sort.bam', 'rb')\n",
    "out_fp = pysam.AlignmentFile('/sc/orga/scratch/bashia02/collaborations/hardik_shah/jason_new/hapcut_outputs/hg002_000000F/hg002.000000F.debug.bam', 'wb', template=bam_fp)\n",
    "hairs_file = '/sc/orga/scratch/bashia02/collaborations/hardik_shah/jason_new/hapcut_outputs/hg002_000000F/hg002_hapcut_000000F.hairs'\n",
    "hapcut_file = '/sc/orga/scratch/bashia02/collaborations/hardik_shah/jason_new/hapcut_outputs/hg002_000000F/hg002_hapcut_000000F.hapcut'\n",
    "\n",
    "hair_reader = HairReader(hairs_file)\n",
    "block_reader = HapCutReader(hapcut_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[506, 507, 518]\n",
      "\n",
      "[510, 511, 512, 514, 516, 517, 519, 520]\n"
     ]
    }
   ],
   "source": [
    "print block_reader.loc(506).variant_ids\n",
    "for i in block_reader.loc(506).informative_reads:\n",
    "    print i\n",
    "    print i.positions\n",
    "    \n",
    "print \"\"\n",
    "print block_reader.loc(510).variant_ids\n",
    "for i in block_reader.loc(510).informative_reads:\n",
    "    print i\n",
    "    print i.positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367158\n",
      "422418\n",
      "[428970, 428970, 434310, 430854, 441741, 441741, 440917, 449473, 453410, 457125, 456724, 456724, 457125, 463311, 466309, 466309, 474637, 471695, 475158, 475866, 482406]\n"
     ]
    }
   ],
   "source": [
    "lastBlock_obj = block_reader.blocks[16]\n",
    "block = block_reader.blocks[17]\n",
    "interblock_reads = block.interblock_reads(lastBlock_obj.informative_reads)\n",
    "#print interblock_reads\n",
    "print lastBlock_obj.start\n",
    "print lastBlock_obj.end\n",
    "print [x.start for x in block.informative_reads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_174943_42177R_c100788362550000001823173308251553_s1_p0/136032/3792_26206\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/89671/0_17273\n",
      "Alleles: 1\n",
      " Hap 1: 2, Hap 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/22778/15931_29708\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150225_013529_42156_c100779742550000001823166508251511_s1_p0/28885/0_3804\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/125623/13816_26172\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/125623/0_13774\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/76317/0_13305\n",
      "Alleles: 1\n",
      " Hap 1: 2, Hap 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_051122_42177R_c100788362550000001823173308251551_s1_p0/29798/0_11028\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/32889/26800_36314\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_175917_42156_c100788292550000001823173308251554_s1_p0/53347/14474_29289\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/50741/4197_24607\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/35077/0_14415\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/126922/0_10741\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/126922/10784_21706\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/126922/33159_42875\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/35527/0_17759\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_205428_42156_c100788292550000001823173308251551_s1_p0/121149/10859_14847\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/28708/0_10166\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_192013_42156_c100779742550000001823166508251510_s1_p0/80619/12666_21760\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_192013_42156_c100779742550000001823166508251510_s1_p0/80619/12666_21760\n",
      "Alleles: 1\n",
      " Hap 1: 0, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/106856/0_12397\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_175917_42156_c100788292550000001823173308251554_s1_p0/112069/15553_27935\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150225_013529_42156_c100779742550000001823166508251511_s1_p0/149666/0_6005\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_124902_42177R_c100788362550000001823173308251556_s1_p0/25894/720_10526\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_114004_42156_c100788292550000001823173308251553_s1_p0/64640/18525_29073\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_192013_42156_c100779742550000001823166508251510_s1_p0/117339/0_9782\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/118208/6450_13454\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_052224_42156_c100788292550000001823173308251552_s1_p0/147345/2921_11641\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_205428_42156_c100788292550000001823173308251551_s1_p0/118223/65745_70932\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/114347/39475_52680\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/125244/0_15192\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/148071/0_8326\n",
      "Alleles: 0\n",
      " Hap 1: 1, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/72377/956_7770\n",
      "Alleles: 1\n",
      " Hap 1: 2, Hap 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_000927_42177R_c100788362550000001823173308251554_s1_p0/120857/0_5961\n",
      "Alleles: 1\n",
      " Hap 1: 2, Hap 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/73192/10203_20230\n",
      "Alleles: 1\n",
      " Hap 1: 2, Hap 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/107710/335_6817\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_001830_42156_c100788292550000001823173308251555_s1_p0/40765/0_22073\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_124902_42177R_c100788362550000001823173308251556_s1_p0/41172/0_11097\n",
      "Alleles: 0\n",
      " Hap 1: 2, Hap 2: 2\n"
     ]
    }
   ],
   "source": [
    "interblock_stats(hair_reader, block_reader, hairs_file + \".interblock_stats.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-430-eca5d994879a>\u001b[0m(148)\u001b[0;36mconcordance\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    147 \u001b[1;33m                    \u001b[0mread_allele\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malleles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 148 \u001b[1;33m                    \u001b[0mhapstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhaplotypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    149 \u001b[1;33m                    \u001b[1;32mif\u001b[0m \u001b[0mhapstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> read\n",
      "<HapCutRead, read_id: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/145946/0_12481>\n",
      "ipdb> read.haplotypes\n",
      "{55: 2}\n",
      "ipdb> self\n",
      "<Block, offset_id: 51>\n",
      "ipdb> read.positions\n",
      "[55, 57, 58]\n",
      "ipdb> block.variant_ids\n",
      "[510, 511, 512, 514, 516, 517, 519, 520]\n",
      "ipdb> self.variant_ids\n",
      "[51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67]\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_174943_42177R_c100788362550000001823173308251553_s1_p0/136032/3792_26206\n",
      "Alleles: ['0', '0', '1']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/89671/0_17273\n",
      "Alleles: ['0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0']\n",
      " Block 1: 2, Block 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/22778/15931_29708\n",
      "Alleles: ['0', '1', '1', '1']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150225_013529_42156_c100779742550000001823166508251511_s1_p0/28885/0_3804\n",
      "Alleles: ['0', '1']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/125623/13816_26172\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/125623/0_13774\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/76317/0_13305\n",
      "Alleles: ['1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0']\n",
      " Block 1: 2, Block 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_051122_42177R_c100788362550000001823173308251551_s1_p0/29798/0_11028\n",
      "Alleles: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/32889/26800_36314\n",
      "Alleles: ['1', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_175917_42156_c100788292550000001823173308251554_s1_p0/53347/14474_29289\n",
      "Alleles: ['0', '1', '0', '0']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/50741/4197_24607\n",
      "Alleles: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/35077/0_14415\n",
      "Alleles: ['1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/126922/0_10741\n",
      "Alleles: ['1', '1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/126922/10784_21706\n",
      "Alleles: ['1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/126922/33159_42875\n",
      "Alleles: ['1', '1', '0', '1', '0', '0', '0', '0', '0', '1']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/35527/0_17759\n",
      "Alleles: ['1', '1', '1', '1', '0', '0', '1', '1']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_205428_42156_c100788292550000001823173308251551_s1_p0/121149/10859_14847\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/28708/0_10166\n",
      "Alleles: ['0', '1', '0', '0']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_192013_42156_c100779742550000001823166508251510_s1_p0/80619/12666_21760\n",
      "Alleles: ['0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_192013_42156_c100779742550000001823166508251510_s1_p0/80619/12666_21760\n",
      "Alleles: ['0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1']\n",
      " Block 1: 0, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/106856/0_12397\n",
      "Alleles: ['1', '1', '1', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_175917_42156_c100788292550000001823173308251554_s1_p0/112069/15553_27935\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150225_013529_42156_c100779742550000001823166508251511_s1_p0/149666/0_6005\n",
      "Alleles: ['0', '1', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_124902_42177R_c100788362550000001823173308251556_s1_p0/25894/720_10526\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_114004_42156_c100788292550000001823173308251553_s1_p0/64640/18525_29073\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_192013_42156_c100779742550000001823166508251510_s1_p0/117339/0_9782\n",
      "Alleles: ['0', '0', '0', '0']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/118208/6450_13454\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_052224_42156_c100788292550000001823173308251552_s1_p0/147345/2921_11641\n",
      "Alleles: ['0', '0', '1']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_205428_42156_c100788292550000001823173308251551_s1_p0/118223/65745_70932\n",
      "Alleles: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/114347/39475_52680\n",
      "Alleles: ['0', '0', '1']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150222_081617_42156_c100777432550000001823160908051597_s1_p0/125244/0_15192\n",
      "Alleles: ['1', '0', '0', '1', '0', '0']\n",
      " Block 1: 2, Block 2: 1\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/148071/0_8326\n",
      "Alleles: ['0', '0', '0', '0', '1', '0', '0', '0']\n",
      " Block 1: 1, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_191026_42177R_c100788362550000001823173308251557_s1_p0/72377/956_7770\n",
      "Alleles: ['0', '0', '0', '0', '0', '1', '0', '1']\n",
      " Block 1: 2, Block 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_000927_42177R_c100788362550000001823173308251554_s1_p0/120857/0_5961\n",
      "Alleles: ['0', '0', '0', '1', '0', '1']\n",
      " Block 1: 2, Block 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_062910_42177R_c100788362550000001823173308251555_s1_p0/73192/10203_20230\n",
      "Alleles: ['0', '0', '0', '0', '0', '1', '1', '1', '1']\n",
      " Block 1: 2, Block 2: 0\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150223_113024_42177R_c100788362550000001823173308251552_s1_p0/107710/335_6817\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 2, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_001830_42156_c100788292550000001823173308251555_s1_p0/40765/0_22073\n",
      "Alleles: ['0', '0', '1', '0', '0']\n",
      " Block 1: 2, Block 2: 2\n",
      "\n",
      "ERROR: read allele matched no haplotypes.\n",
      "\n",
      "Hair read: m150224_124902_42177R_c100788362550000001823173308251556_s1_p0/41172/0_11097\n",
      "Alleles: ['0', '0']\n",
      " Block 1: 2, Block 2: 2\n"
     ]
    }
   ],
   "source": [
    "read = None\n",
    "for read in hair_reader.reads:\n",
    "    read2 = greedy_partition(read, block_reader)\n",
    "    if read2.blockcount > 1:\n",
    "        print read2.blocks\n",
    "        print read2.haplotypes, read2.blockcount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
