{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minerva4\r\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports / style (run this first always)\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from IPython.core import display\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "class AwesomeError(Exception):\n",
    "     def __init__(self, value):\n",
    "         self.value = value\n",
    "         pass\n",
    "     def __str__(self):\n",
    "         return repr(self.value)\n",
    "         pass\n",
    "\n",
    "#colorbrewer2 Dark2 qualitative color table\n",
    "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
    "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
    "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
    "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
    "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
    "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843)]\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['figure.dpi'] = 150\n",
    "rcParams['axes.color_cycle'] = dark2_colors\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['patch.facecolor'] = dark2_colors[0]\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "\n",
    "\n",
    "def remove_border(axes=None, top=False, right=False, left=True, bottom=True):\n",
    "    \"\"\"\n",
    "    Minimize chartjunk by stripping out unnecesasry plot borders and axis ticks\n",
    "    \n",
    "    The top/right/left/bottom keywords toggle whether the corresponding plot border is drawn\n",
    "    \"\"\"\n",
    "    ax = axes or plt.gca()\n",
    "    ax.spines['top'].set_visible(top)\n",
    "    ax.spines['right'].set_visible(right)\n",
    "    ax.spines['left'].set_visible(left)\n",
    "    ax.spines['bottom'].set_visible(bottom)\n",
    "    \n",
    "    #turn off all ticks\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    \n",
    "    #now re-enable visibles\n",
    "    if top:\n",
    "        ax.xaxis.tick_top()\n",
    "    if bottom:\n",
    "        ax.xaxis.tick_bottom()\n",
    "    if left:\n",
    "        ax.yaxis.tick_left()\n",
    "    if right:\n",
    "        ax.yaxis.tick_right()\n",
    "        \n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import Bio as bp\n",
    "from Bio.Sequencing.Applications import BwaAlignCommandline as bwa_aln\n",
    "from Bio.Sequencing.Applications import BwaSamseCommandline as bwa_samse\n",
    "from Bio.Sequencing.Applications import BwaSampeCommandline as bwa_sampe\n",
    "from Bio.Sequencing.Applications import BwaIndexCommandline as bwa_index\n",
    "from Bio.Sequencing.Applications import BwaBwaswCommandline as bwa_bwasw\n",
    "import HTSeq as ht\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "\n",
    "class BlockVariant:\n",
    "    def __init__ (self, variantline):\n",
    "        # variant_id haplotype_1 haplotype_2 chromosome position refallele variantallele genotype allele_counts:genotype_likelihoods:delta:MEC_variant\n",
    "        ll = variantline.strip().split(\"\\t\")\n",
    "        var_id, hap1, hap2, chrom, pos, r_allele, v_allele, genotype, info_str = ll\n",
    "        self.var_id, self.hap1, self.hap2, self.pos = int(var_id), int(hap1), int(hap2), int(pos)\n",
    "        allele_counts, genotype_likelihoods, delta, MEC_variant = info_str.split(\":\")\n",
    "        self.ref_count, self.alt_count = map(int, allele_counts.split(\",\"))\n",
    "        gen_00, gen_01, gen_11 = map(float, genotype_likelihoods.split(\",\"))\n",
    "        self.gen_like = {\"0/0\":gen_00, \"0/1\":gen_01, \"1/1\":gen_11}\n",
    "        self.delta = float(delta)\n",
    "        self.MEC_variant = MEC_variant\n",
    "\n",
    "\n",
    "class Block:\n",
    "    def __init__ (self, blockline):\n",
    "        # \"BLOCK: offset:\" first_variant_block \"len:\" length_of_block \"phased\": phased_variants_block SPAN: \n",
    "        # lengthspanned MECscore score fragments #fragments\n",
    "        \n",
    "        ll               = blockline.strip().split()\n",
    "        self.offset      = int(ll[2])\n",
    "        self.total_len   = int(ll[4])\n",
    "        self.phased      = int(ll[6])\n",
    "        self.span        = int(ll[8])\n",
    "        self.MECscore    = float(ll[10])\n",
    "        self.fragments   = int(ll[12])\n",
    "        variants = [] # default to empty\n",
    "\n",
    "    def addVariant (variantline):\n",
    "        variants.append(BlockVariant(variantline))\n",
    "\n",
    "\n",
    "class HapCutReader:\n",
    "    \n",
    "    def __init__ ( self, fn ):\n",
    "        self.blocks = read_file_to_blocks (fn)\n",
    "        \n",
    "\n",
    "    def read_file_to_blocks (self, fn):\n",
    "        with open (hapcutoutfn) as f:\n",
    "            f.readline()\n",
    "            blocks = []\n",
    "            currBlock = None\n",
    "            prevBlock = False\n",
    "            for l in f:\n",
    "                if l[0] == \"B\":\n",
    "                    if prevBlock:\n",
    "                        yield block, snpDict\n",
    "                    else:\n",
    "                        prevBlock = True\n",
    "                        currBlock = Block(l)\n",
    "                else:\n",
    "                    currBlock.addVariant(l)\n",
    "\n",
    "                        \n",
    "\n",
    "class HapCutRead:\n",
    "\n",
    "    def __init__ (self, hairline):\n",
    "        #Column 1 is the number of blocks (consecutive set of SNPs covered by the fragment). \n",
    "        #Column 2 is the fragment id. \n",
    "        #Column 3 is the offset of the first block of SNPs covered by the fragment followed by the alleles at the SNPs in this block.\n",
    "        #Column 5 is the offset of the second block of SNPs covered by the fragment followed by the alleles at the SNPs in this block.\n",
    "        #...\n",
    "        #The last column is a string with the quality values (Sanger fastq format) for all the alleles covered by the fragment (concatenated for all blocks). \n",
    "        #For example, if a read/fragment covers SNPs 2,3 and 5 with the alleles 0, 1 and 0 respectively, then the input will be:\n",
    "        #2 read_id 2 01 5 0 AAC\n",
    "        #Here AAC is the string corresponding to the quality values at the three alleles. The encoding of 0/1 is arbitrary but following the VCF format, 0 is reference and 1 is alternate. \n",
    "        hairlist = hairline.strip().split()\n",
    "        self.blockcount = int(hairlist[0])     # number of blocks\n",
    "        self.read_id    = hairlist[1]          # read_id\n",
    "        positions       = []                   # an array with the indices covered by read\n",
    "        alleles         = []                   # a matched array with the allele calls at each position\n",
    "        for i in range(2, len(hairlist)-1, 2):\n",
    "            position = hairlist[i]\n",
    "            allele = hairlist[i+1]\n",
    "            positions.extend(range(position, position+len(allele)))\n",
    "            alleles.extend(allele)\n",
    "        self.qualities  = hairlist[-1]         # a matched arary of the qualities of allele calls\n",
    "\n",
    "class HairReader:\n",
    "\n",
    "    def __init__ (self, fn):\n",
    "        self.reads = []\n",
    "        with open (fn) as f:\n",
    "            for l in f:\n",
    "                self.reads.append(HapCutRead(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "extract_reads\n",
    "Ryan Neff\n",
    "7/5/2015\n",
    "\n",
    "Usage: Extracts reads from a bam file corresponding to a particular haplotype, with haplotype\n",
    "definitions from HapCut, and places them into a separate file.\n",
    "\n",
    "Inputs:\n",
    "    bam_file (string)\n",
    "        The filename of a bam file on which the haplotype cuts were generated.\n",
    "    read_array (list of <HapCutRead>)\n",
    "        An array of HapCutRead objects that list which reads correspond to a particular haplotype block.\n",
    "    blockvar_array (list of <BlockVariants>)\n",
    "        An array of all BlockVariant objects in read_array that help convert read blocks to chromosomal positions. \n",
    "Outputs:\n",
    "    out_file (string)\n",
    "        The filename of the output (bam file).\n",
    "        \n",
    "'''\n",
    "\n",
    "# required imports - additional to ipy_setup.py\n",
    "import pysam\n",
    "import subprocess\n",
    "from itertools import groupby\n",
    "\n",
    "def extract_reads(bam_file, read_array, blockvar_array, out_file):\n",
    "    assert pysam.Samfile(bam_file, 'rb'), 'ERROR: Cannot open bam file for reading.'\n",
    "    bam_fp = pysam.Samfile(bam_file, 'rb')\n",
    "    \n",
    "    if out_file==None:\n",
    "        out_file = bam_file + \".extract_reads_\" + time.strftime(\"%m%d%y_%H%M%S\") + '.bam'\n",
    "    \n",
    "    assert pysam.AlignmentFile(out_file, \"wb\", template=bam_fp), 'ERROR: Cannot open output file for writing.'\n",
    "    out_fp = pysam.AlignmentFile(out_file, \"wb\", template=bam_fp)\n",
    "    \n",
    "    # let's group the reads by read.positions[0] to speed up reading from the BAM file    \n",
    "    for block_id, reads in groupby(read_array, lambda x: x.positions[0]):\n",
    "        \n",
    "        block = next((x for x in blockvar_array if x.var_id == block_id), None) # retrieve block\n",
    "       \n",
    "        for bamread in bam_fp.pileup(block.chrom, block.pos, block.pos + 1):  # get reads from bamfile\n",
    "            if bamread.id in reads:\n",
    "                out_fp.write(bamread) # we've found a read from the group, so output it\n",
    "            else:\n",
    "                continue # this is a non-informative read, so ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greedy_partitioner(read_array, blockvar_array, out_b1, out_b2, out_am):\n",
    "    '''\n",
    "        for read in read_array: \n",
    "        translate hairfile alleles into blockvar IDs\n",
    "        get alleles in each read spanning blockvars\n",
    "        determine alleles for the two blocks from blockvar\n",
    "        partition reads based on locally most probable alignment\n",
    "        \n",
    "    '''\n",
    "    for read in read_array:\n",
    "        allele_state = []\n",
    "        for ix, readpos in enumerate(read.positions):\n",
    "            block = next((x for x in blockvar_array if x.var_id == block_id), None)\n",
    "            if block.hap1 == read.alleles[readpos]:\n",
    "                allele_state.append(-1)\n",
    "            elif block.hap2 == read.alleles[readpos]:\n",
    "                allele_state.append(1)\n",
    "            else:\n",
    "                print \"Unexpected error: read allele matched no haplotypes.\"\n",
    "                raise\n",
    "        if sum(allele_state) < 0:\n",
    "            out_b1.append(read)\n",
    "        elif sum(allele_state) > 0:\n",
    "            out_b2.append(read)\n",
    "        else:\n",
    "            out_am.append(read)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
